is_train: True 
out_root_path: /outputs/audio2pose/ 
train_data_path: /datasets/beat_cache/beat_4english_15_141/train/ 
val_data_path: /datasets/beat_cache/beat_4english_15_141/val/ 
test_data_path: /datasets/beat_cache/beat_4english_15_141/test/ 
mean_pose_path: /datasets/beat_cache/beat_4english_15_141/train/
std_pose_path: /datasets/beat_cache/beat_4english_15_141/train/
torch_hub_path: /datasets/checkpoints/ 
dataset: beat
new_cache: True
pose_rep: bvh_rot
audio_rep: wave16k
facial_rep: facial52
word_rep: text
emo_rep: emo
sem_rep: sem
speaker_id: False
audio_norm: True
facial_norm: True
pose_dims: 141
batch_size: 256
test_period: 20
pose_length: 34
stride: 10
vae_length: 300
hidden_size: 128
g_name: EmbeddingNet 
model: motion_autoencoder
trainer: ae
variational_encoding: False
rec_weight: 1
vel_weight: 0.1
kld_weight: 0
lr_base: 0.00012 
grad_norm: 0
epochs: 140